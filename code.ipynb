{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58c8d973",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58c8d973",
    "outputId": "5e9cb5a6-af0f-421c-adf8-7e69cbca6ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /opt/anaconda3/lib/python3.12/site-packages (8.3.27)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from ultralytics) (3.9.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from ultralytics) (2.5.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from ultralytics) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/anaconda3/lib/python3.12/site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.12/site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/anaconda3/lib/python3.12/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/anaconda3/lib/python3.12/site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from ultralytics) (2.0.10)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f365dd5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2f365dd5",
    "outputId": "5cbdb317-4ecd-426a-ccbf-33681c50fe76"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ed17438",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ed17438",
    "outputId": "e56d53a7-243c-4c1c-b09e-c61e5426915a"
   },
   "outputs": [],
   "source": [
    "#YOLOv8 model(on COCO dataset)\n",
    "model = YOLO('yolov8s.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aae8696",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2aae8696",
    "outputId": "ab7f00ef-84ab-4675-e318-007ada8650fa"
   },
   "outputs": [],
   "source": [
    "#Reading input\n",
    "video_path = \"/Users/manindragurung/Desktop/video/2.mp4\"\n",
    "\n",
    "if not os.path.isfile(video_path):\n",
    "    raise FileNotFoundError(f\"Video file not found at {video_path}\")\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise IOError(f\"Failed to open video file at {video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2cb5aa6",
   "metadata": {
    "id": "a2cb5aa6"
   },
   "outputs": [],
   "source": [
    "#Saving output\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  \n",
    "output_path = \"/Users/manindragurung/Desktop/video/op1011.mp4\"\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))  # Frames per second of the input video\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0268b015-0a58-48b2-b494-c37507f19343",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Threshold\n",
    "proximity_threshold = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "317883c8-e48b-4d0d-9628-7cb829c640e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Colors for each group\n",
    "highlight_group = 1\n",
    "group_colors = [(0, 255, 0), (0, 0, 255), (255, 0, 0), (0, 255, 255), (255, 0, 255), (255, 255, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c482608c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "c482608c",
    "outputId": "de6762ba-1231-44bf-f156-21a4f2903fb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 22 persons, 1 handbag, 2 skateboards, 105.9ms\n",
      "Speed: 3.5ms preprocess, 105.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 1 skateboard, 88.6ms\n",
      "Speed: 1.6ms preprocess, 88.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 1 skateboard, 101.2ms\n",
      "Speed: 1.4ms preprocess, 101.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 1 handbag, 3 skateboards, 122.2ms\n",
      "Speed: 1.3ms preprocess, 122.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 3 skateboards, 84.2ms\n",
      "Speed: 1.4ms preprocess, 84.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 3 skateboards, 82.3ms\n",
      "Speed: 1.4ms preprocess, 82.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 1 backpack, 2 skateboards, 78.5ms\n",
      "Speed: 1.4ms preprocess, 78.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 persons, 1 backpack, 2 handbags, 2 skateboards, 78.1ms\n",
      "Speed: 2.2ms preprocess, 78.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 persons, 1 backpack, 2 handbags, 4 skateboards, 75.9ms\n",
      "Speed: 1.5ms preprocess, 75.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 persons, 1 backpack, 3 skateboards, 73.6ms\n",
      "Speed: 1.4ms preprocess, 73.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 1 backpack, 4 skateboards, 75.8ms\n",
      "Speed: 1.8ms preprocess, 75.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 1 backpack, 3 skateboards, 69.2ms\n",
      "Speed: 1.4ms preprocess, 69.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 2 backpacks, 3 skateboards, 75.3ms\n",
      "Speed: 1.3ms preprocess, 75.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 persons, 3 backpacks, 3 skateboards, 81.8ms\n",
      "Speed: 1.3ms preprocess, 81.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 persons, 1 backpack, 4 skateboards, 81.4ms\n",
      "Speed: 1.3ms preprocess, 81.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 2 backpacks, 1 skateboard, 80.9ms\n",
      "Speed: 1.3ms preprocess, 80.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 persons, 1 backpack, 1 skateboard, 81.6ms\n",
      "Speed: 1.8ms preprocess, 81.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 2 skateboards, 73.8ms\n",
      "Speed: 1.9ms preprocess, 73.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 2 skateboards, 72.7ms\n",
      "Speed: 1.4ms preprocess, 72.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 2 skateboards, 76.6ms\n",
      "Speed: 1.3ms preprocess, 76.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 2 backpacks, 1 handbag, 2 skateboards, 69.4ms\n",
      "Speed: 1.3ms preprocess, 69.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 1 backpack, 1 skateboard, 76.3ms\n",
      "Speed: 1.4ms preprocess, 76.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 2 backpacks, 1 skateboard, 82.6ms\n",
      "Speed: 1.3ms preprocess, 82.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 1 backpack, 1 handbag, 2 skateboards, 73.5ms\n",
      "Speed: 1.4ms preprocess, 73.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 2 backpacks, 1 skateboard, 83.0ms\n",
      "Speed: 2.2ms preprocess, 83.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 2 backpacks, 2 skateboards, 77.7ms\n",
      "Speed: 1.4ms preprocess, 77.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 1 backpack, 2 skateboards, 80.1ms\n",
      "Speed: 1.5ms preprocess, 80.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 2 backpacks, 2 skateboards, 81.0ms\n",
      "Speed: 1.2ms preprocess, 81.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 2 backpacks, 1 handbag, 1 skateboard, 74.3ms\n",
      "Speed: 1.2ms preprocess, 74.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 2 backpacks, 1 handbag, 1 skateboard, 75.5ms\n",
      "Speed: 1.5ms preprocess, 75.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 1 backpack, 1 handbag, 1 skateboard, 73.0ms\n",
      "Speed: 1.4ms preprocess, 73.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 1 backpack, 1 skateboard, 72.4ms\n",
      "Speed: 1.4ms preprocess, 72.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 1 skateboard, 69.0ms\n",
      "Speed: 1.4ms preprocess, 69.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 persons, 1 backpack, 1 skateboard, 78.9ms\n",
      "Speed: 1.3ms preprocess, 78.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 persons, 2 skateboards, 73.1ms\n",
      "Speed: 1.4ms preprocess, 73.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 persons, 2 skateboards, 68.5ms\n",
      "Speed: 1.4ms preprocess, 68.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 1 skateboard, 70.7ms\n",
      "Speed: 1.1ms preprocess, 70.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 25 persons, 1 skateboard, 69.6ms\n",
      "Speed: 1.1ms preprocess, 69.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 persons, 1 skateboard, 71.1ms\n",
      "Speed: 1.5ms preprocess, 71.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 persons, 3 skateboards, 71.8ms\n",
      "Speed: 1.3ms preprocess, 71.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 persons, 2 skateboards, 69.9ms\n",
      "Speed: 1.2ms preprocess, 69.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 persons, 2 skateboards, 82.8ms\n",
      "Speed: 1.2ms preprocess, 82.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 1 backpack, 4 skateboards, 71.4ms\n",
      "Speed: 1.4ms preprocess, 71.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 persons, 1 backpack, 4 skateboards, 66.0ms\n",
      "Speed: 1.4ms preprocess, 66.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 persons, 4 skateboards, 73.7ms\n",
      "Speed: 1.3ms preprocess, 73.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 1 backpack, 1 handbag, 5 skateboards, 63.1ms\n",
      "Speed: 1.3ms preprocess, 63.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 1 backpack, 3 skateboards, 65.4ms\n",
      "Speed: 1.2ms preprocess, 65.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 1 backpack, 1 handbag, 4 skateboards, 61.2ms\n",
      "Speed: 1.4ms preprocess, 61.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 2 backpacks, 1 handbag, 2 skateboards, 62.8ms\n",
      "Speed: 1.2ms preprocess, 62.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 persons, 1 handbag, 2 skateboards, 63.5ms\n",
      "Speed: 1.3ms preprocess, 63.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 persons, 1 handbag, 2 skateboards, 64.1ms\n",
      "Speed: 1.2ms preprocess, 64.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 2 skateboards, 59.8ms\n",
      "Speed: 1.3ms preprocess, 59.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 persons, 1 handbag, 2 skateboards, 63.1ms\n",
      "Speed: 1.4ms preprocess, 63.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 persons, 2 skateboards, 63.3ms\n",
      "Speed: 1.1ms preprocess, 63.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 persons, 1 handbag, 1 skateboard, 64.6ms\n",
      "Speed: 1.5ms preprocess, 64.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 persons, 1 skateboard, 65.2ms\n",
      "Speed: 1.3ms preprocess, 65.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 persons, 1 handbag, 3 skateboards, 63.3ms\n",
      "Speed: 1.7ms preprocess, 63.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 persons, 2 skateboards, 61.0ms\n",
      "Speed: 1.5ms preprocess, 61.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 persons, 2 skateboards, 65.1ms\n",
      "Speed: 1.2ms preprocess, 65.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 persons, 2 skateboards, 62.7ms\n",
      "Speed: 1.5ms preprocess, 62.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 persons, 1 skateboard, 64.7ms\n",
      "Speed: 1.2ms preprocess, 64.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 persons, 1 handbag, 1 skateboard, 80.4ms\n",
      "Speed: 1.4ms preprocess, 80.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 25 persons, 1 skateboard, 68.1ms\n",
      "Speed: 1.4ms preprocess, 68.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 25 persons, 1 handbag, 1 skateboard, 67.8ms\n",
      "Speed: 1.6ms preprocess, 67.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 persons, 1 skateboard, 68.1ms\n",
      "Speed: 1.3ms preprocess, 68.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 persons, 1 skateboard, 70.7ms\n",
      "Speed: 1.3ms preprocess, 70.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 persons, 1 handbag, 1 skateboard, 78.6ms\n",
      "Speed: 1.3ms preprocess, 78.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 25 persons, 1 handbag, 1 skateboard, 66.2ms\n",
      "Speed: 1.4ms preprocess, 66.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 persons, 1 handbag, 1 skateboard, 61.3ms\n",
      "Speed: 1.3ms preprocess, 61.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 25 persons, 1 handbag, 1 skateboard, 65.7ms\n",
      "Speed: 1.4ms preprocess, 65.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 persons, 1 handbag, 1 skateboard, 61.4ms\n",
      "Speed: 1.2ms preprocess, 61.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 persons, 2 handbags, 1 skateboard, 65.5ms\n",
      "Speed: 1.3ms preprocess, 65.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 persons, 2 handbags, 1 skateboard, 64.9ms\n",
      "Speed: 1.2ms preprocess, 64.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 25 persons, 2 handbags, 1 skateboard, 63.3ms\n",
      "Speed: 1.2ms preprocess, 63.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 persons, 1 skateboard, 63.7ms\n",
      "Speed: 1.2ms preprocess, 63.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 27 persons, 2 skateboards, 67.8ms\n",
      "Speed: 1.5ms preprocess, 67.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 persons, 2 skateboards, 63.6ms\n",
      "Speed: 1.3ms preprocess, 63.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 persons, 1 handbag, 2 skateboards, 62.1ms\n",
      "Speed: 1.2ms preprocess, 62.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 persons, 1 handbag, 2 skateboards, 63.6ms\n",
      "Speed: 1.6ms preprocess, 63.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 25 persons, 1 handbag, 2 skateboards, 63.6ms\n",
      "Speed: 1.3ms preprocess, 63.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 27 persons, 1 handbag, 2 skateboards, 72.9ms\n",
      "Speed: 1.3ms preprocess, 72.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 27 persons, 1 handbag, 2 skateboards, 62.8ms\n",
      "Speed: 1.5ms preprocess, 62.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 persons, 3 handbags, 1 skateboard, 66.1ms\n",
      "Speed: 1.5ms preprocess, 66.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 persons, 2 handbags, 1 skateboard, 69.8ms\n",
      "Speed: 1.3ms preprocess, 69.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 persons, 1 handbag, 1 skateboard, 64.2ms\n",
      "Speed: 1.5ms preprocess, 64.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 persons, 1 handbag, 3 skateboards, 65.3ms\n",
      "Speed: 1.3ms preprocess, 65.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 25 persons, 1 backpack, 3 skateboards, 63.1ms\n",
      "Speed: 1.4ms preprocess, 63.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 27 persons, 4 skateboards, 64.6ms\n",
      "Speed: 1.3ms preprocess, 64.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 persons, 5 skateboards, 62.9ms\n",
      "Speed: 1.6ms preprocess, 62.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 27 persons, 1 backpack, 2 skateboards, 62.3ms\n",
      "Speed: 1.2ms preprocess, 62.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 27 persons, 1 backpack, 2 skateboards, 64.3ms\n",
      "Speed: 1.4ms preprocess, 64.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 persons, 2 backpacks, 2 skateboards, 66.3ms\n",
      "Speed: 1.3ms preprocess, 66.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 persons, 2 backpacks, 2 skateboards, 62.8ms\n",
      "Speed: 1.2ms preprocess, 62.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 28 persons, 2 backpacks, 1 handbag, 2 skateboards, 63.9ms\n",
      "Speed: 1.2ms preprocess, 63.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 28 persons, 1 backpack, 1 skateboard, 65.0ms\n",
      "Speed: 1.3ms preprocess, 65.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 27 persons, 1 backpack, 1 handbag, 1 skateboard, 64.5ms\n",
      "Speed: 1.3ms preprocess, 64.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 28 persons, 3 backpacks, 3 handbags, 65.0ms\n",
      "Speed: 1.6ms preprocess, 65.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 27 persons, 3 backpacks, 2 handbags, 1 skateboard, 65.3ms\n",
      "Speed: 1.6ms preprocess, 65.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 27 persons, 3 backpacks, 1 handbag, 1 skateboard, 64.8ms\n",
      "Speed: 1.3ms preprocess, 64.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 persons, 3 backpacks, 2 handbags, 1 skateboard, 62.8ms\n",
      "Speed: 1.6ms preprocess, 62.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 persons, 3 backpacks, 1 skateboard, 65.9ms\n",
      "Speed: 1.3ms preprocess, 65.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 persons, 2 backpacks, 1 handbag, 1 skateboard, 65.9ms\n",
      "Speed: 1.4ms preprocess, 65.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 27 persons, 3 backpacks, 1 handbag, 1 skateboard, 63.9ms\n",
      "Speed: 1.3ms preprocess, 63.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 27 persons, 4 backpacks, 1 handbag, 1 skateboard, 65.8ms\n",
      "Speed: 1.2ms preprocess, 65.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 30 persons, 3 backpacks, 1 handbag, 1 skateboard, 65.8ms\n",
      "Speed: 1.4ms preprocess, 65.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 28 persons, 4 backpacks, 1 handbag, 1 skateboard, 63.1ms\n",
      "Speed: 1.4ms preprocess, 63.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 29 persons, 2 backpacks, 1 skateboard, 66.2ms\n",
      "Speed: 1.3ms preprocess, 66.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 28 persons, 4 backpacks, 1 skateboard, 65.7ms\n",
      "Speed: 1.6ms preprocess, 65.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 27 persons, 3 backpacks, 1 handbag, 67.8ms\n",
      "Speed: 1.3ms preprocess, 67.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 27 persons, 1 backpack, 1 handbag, 1 skateboard, 65.1ms\n",
      "Speed: 1.5ms preprocess, 65.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 25 persons, 2 backpacks, 1 handbag, 64.3ms\n",
      "Speed: 1.2ms preprocess, 64.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 persons, 1 handbag, 1 skateboard, 63.4ms\n",
      "Speed: 1.2ms preprocess, 63.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 persons, 1 skateboard, 67.6ms\n",
      "Speed: 1.2ms preprocess, 67.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 persons, 1 handbag, 1 skateboard, 64.4ms\n",
      "Speed: 1.4ms preprocess, 64.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 persons, 1 skateboard, 64.7ms\n",
      "Speed: 1.6ms preprocess, 64.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 27 persons, 1 backpack, 1 handbag, 1 skateboard, 65.1ms\n",
      "Speed: 1.2ms preprocess, 65.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 persons, 1 skateboard, 65.0ms\n",
      "Speed: 1.2ms preprocess, 65.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 persons, 1 skateboard, 69.7ms\n",
      "Speed: 1.6ms preprocess, 69.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 25 persons, 1 skateboard, 63.2ms\n",
      "Speed: 1.4ms preprocess, 63.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 27 persons, 1 handbag, 1 skateboard, 64.9ms\n",
      "Speed: 1.5ms preprocess, 64.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 persons, 63.9ms\n",
      "Speed: 1.5ms preprocess, 63.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 27 persons, 1 handbag, 1 skateboard, 66.9ms\n",
      "Speed: 1.3ms preprocess, 66.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 persons, 1 handbag, 1 skateboard, 62.9ms\n",
      "Speed: 1.4ms preprocess, 62.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 persons, 1 backpack, 1 handbag, 1 skateboard, 68.3ms\n",
      "Speed: 1.2ms preprocess, 68.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 27 persons, 1 backpack, 1 handbag, 1 skateboard, 68.0ms\n",
      "Speed: 1.3ms preprocess, 68.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 25 persons, 1 backpack, 3 handbags, 1 skateboard, 73.4ms\n",
      "Speed: 2.5ms preprocess, 73.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 persons, 1 backpack, 2 handbags, 66.9ms\n",
      "Speed: 1.3ms preprocess, 66.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 persons, 1 backpack, 3 handbags, 68.4ms\n",
      "Speed: 1.2ms preprocess, 68.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 persons, 1 backpack, 2 handbags, 65.5ms\n",
      "Speed: 1.4ms preprocess, 65.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 26 persons, 1 backpack, 1 handbag, 66.1ms\n",
      "Speed: 1.4ms preprocess, 66.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 27 persons, 1 backpack, 1 handbag, 1 skateboard, 65.2ms\n",
      "Speed: 1.6ms preprocess, 65.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 27 persons, 2 backpacks, 1 handbag, 1 skateboard, 69.9ms\n",
      "Speed: 1.5ms preprocess, 69.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 28 persons, 2 backpacks, 1 skateboard, 67.9ms\n",
      "Speed: 1.6ms preprocess, 67.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Capturing frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    #Running YOLOv8 on the frame\n",
    "    results = model(frame)  \n",
    "\n",
    "    people_boxes = [] \n",
    "\n",
    "    # Loop over the detected objects\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            cls = int(box.cls[0])  \n",
    "            #Process 'person' class\n",
    "            if model.names[cls] == 'person': \n",
    "                #Confidence score\n",
    "                conf = box.conf[0]  \n",
    "                if conf > 0.5:  \n",
    "                    \n",
    "                    #Bounding box coordinates\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    \n",
    "                    #Calculating the center of the bounding box\n",
    "                    center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "                    people_boxes.append((center_x, center_y))\n",
    "                    \n",
    "                    #Drawing bounding box and label on the frame\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)  \n",
    "                    label = f'Person {conf:.2f}'\n",
    "                    cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "    #Counting number of people\n",
    "    num_people = len(people_boxes)\n",
    "    groups = [] \n",
    "\n",
    "     #Checking for groups \n",
    "    if num_people > 1:  \n",
    "        \n",
    "        #Tracking which people have been grouped\n",
    "        visited = [False] * num_people  \n",
    "        for i in range(num_people):\n",
    "            if visited[i]:\n",
    "                continue\n",
    "            group = [i]\n",
    "            for j in range(i + 1, num_people):\n",
    "                \n",
    "                #Calculating the Euclidean distance \n",
    "                distance = np.sqrt((people_boxes[i][0] - people_boxes[j][0]) ** 2 + (people_boxes[i][1] - people_boxes[j][1]) ** 2)\n",
    "\n",
    "                #Checking the distance \n",
    "                if distance < proximity_threshold:\n",
    "                    group.append(j)\n",
    "                    visited[j] = True\n",
    "            if len(group) > 1:  \n",
    "                groups.append(group)\n",
    "    #Displaying\n",
    "    cv2.putText(frame, f'People: {num_people}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    #Displaying group \n",
    "    for idx, group in enumerate(groups):\n",
    "        group_color = group_colors[idx % len(group_colors)]  \n",
    "        group_size = len(group)\n",
    "        group_label = f'Group {idx + 1}: {group_size} people'\n",
    "        color = (0, 255, 255) if (idx + 1) == highlight_group else group_color\n",
    "\n",
    "        #Drawing bounding boxes around the group members \n",
    "        for member_index in group:\n",
    "            center_x, center_y = people_boxes[member_index]\n",
    "            cv2.circle(frame, (center_x, center_y), 10, color, -1)\n",
    "    \n",
    "    out.write(frame)\n",
    "\n",
    "    #Displaying the frame with detections\n",
    "    cv2.imshow('Output', frame)\n",
    "\n",
    "    #Breaking the loop \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19d7f32",
   "metadata": {
    "id": "c19d7f32"
   },
   "outputs": [],
   "source": [
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
